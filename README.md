# Review-for-Paper

http://www.leiphone.com/news/201703/Isacz6x6dDNQPDVW.html

http://www.leiphone.com/news/201610/SqlyIRXlACv8UsId.html?utm_source=tuicool&utm_medium=referral

http://www.jianshu.com/nb/8413272


http://blog.csdn.net/langb2014/article/details/53036216


\subsection{[Paper] Perceptual Losses for Real-Time Style Transfer and Super-Resolution}
In engineering practice, it is far from enough to realize the code.

They combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. 

They show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. 

Compared to the optimization-based method, they network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.

\sudsection{[Implementation] Fast transfer style}
They implementation is based off of a combination of Gatys' <<A Neural Algorithm of Artistic Style>>, Johnson's <<Perceptual Losses for Real-Time Style Transfer and Super-Resolution >>, and Ulyanov's <<Instance Normalization>>.

The most interesting thing is $Video Stylization$

It is AMZATION.
